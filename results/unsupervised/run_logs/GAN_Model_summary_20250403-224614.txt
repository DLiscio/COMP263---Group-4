==================================================
GAN MODEL TRAINING CONFIGURATION
==================================================

-------------------- Training Parameters --------------------
Batch Size: 128
Latent Dimension: 64
Epochs: 15

-------------------- Loss & Optimizers --------------------
Loss Function: BinaryCrossentropy

Generator Optimizer (Adam):
Learning Rate: 0.00019999999494757503
Beta 1: 0.5

Discriminator Optimizer (Adam):
Learning Rate: 0.00019999999494757503
Beta 1: 0.5
==================================================
MODEL ARCHITECTURES
==================================================

-------------------- Generator Architecture --------------------
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                        │ (None, 18432)               │       1,179,648 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 18432)               │          73,728 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu (LeakyReLU)              │ (None, 18432)               │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ reshape (Reshape)                    │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose (Conv2DTranspose)   │ (None, 48, 48, 64)          │         131,072 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 48, 48, 64)          │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_1 (LeakyReLU)            │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose_1 (Conv2DTranspose) │ (None, 96, 96, 1)           │           1,024 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 1,385,728 (5.29 MB)
 Trainable params: 1,348,736 (5.15 MB)
 Non-trainable params: 36,992 (144.50 KB)


-------------------- Discriminator Architecture --------------------
Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                      │ (None, 48, 48, 64)          │           1,088 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_2 (LeakyReLU)            │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 12, 12, 128)         │         131,200 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_3 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 18432)               │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │          18,433 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 150,721 (588.75 KB)
 Trainable params: 150,721 (588.75 KB)
 Non-trainable params: 0 (0.00 B)


==================================================
TRAINING RESULTS FOLLOW BELOW
==================================================

Epoch, Time(s), Generator_Loss, Discriminator_Loss
1, 73.90, 1.0850, 1.0266
2, 70.62, 0.9279, 1.2069
3, 71.04, 0.6557, 1.4689
4, 73.31, 0.7563, 1.3415
5, 76.56, 0.6874, 1.4120
6, 71.57, 0.6832, 1.4632
7, 71.10, 0.7224, 1.3798
8, 71.12, 0.6937, 1.4136
9, 71.89, 0.6823, 1.4452
10, 72.06, 0.7125, 1.3903
11, 70.95, 0.6831, 1.4438
12, 74.22, 0.6864, 1.4152
13, 73.30, 0.7500, 1.3349
14, 71.74, 0.7410, 1.3455
15, 71.99, 0.7426, 1.3686
