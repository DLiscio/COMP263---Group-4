==================================================
GAN MODEL TRAINING CONFIGURATION
==================================================

-------------------- Training Parameters --------------------
Batch Size: 256
Latent Dimension: 128
Epochs: 10

-------------------- Loss & Optimizers --------------------
Loss Function: BinaryCrossentropy

Generator Optimizer (Adam):
Learning Rate: 0.00019999999494757503
Beta 1: 0.5

Discriminator Optimizer (Adam):
Learning Rate: 0.00019999999494757503
Beta 1: 0.5
==================================================
MODEL ARCHITECTURES
==================================================

-------------------- Generator Architecture --------------------
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                        │ (None, 18432)               │       2,359,296 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 18432)               │          73,728 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu (LeakyReLU)              │ (None, 18432)               │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ reshape (Reshape)                    │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose (Conv2DTranspose)   │ (None, 48, 48, 64)          │         131,072 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 48, 48, 64)          │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_1 (LeakyReLU)            │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose_1 (Conv2DTranspose) │ (None, 96, 96, 1)           │           1,024 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 2,565,376 (9.79 MB)
 Trainable params: 2,528,384 (9.65 MB)
 Non-trainable params: 36,992 (144.50 KB)


-------------------- Discriminator Architecture --------------------
Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                      │ (None, 48, 48, 64)          │           1,088 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_2 (LeakyReLU)            │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout (Dropout)                    │ (None, 48, 48, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 12, 12, 128)         │         131,200 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_3 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dropout_1 (Dropout)                  │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 18432)               │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │          18,433 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 150,721 (588.75 KB)
 Trainable params: 150,721 (588.75 KB)
 Non-trainable params: 0 (0.00 B)


==================================================
TRAINING RESULTS FOLLOW BELOW
==================================================

Epoch, Time(s), Generator_Loss, Discriminator_Loss
1, 82.59, 1.1447, 0.8453
2, 77.04, 1.2586, 0.9881
3, 75.16, 1.1537, 0.9005
4, 77.68, 0.7271, 1.4344
5, 76.36, 0.6068, 1.5511
6, 77.38, 0.7629, 1.2939
7, 77.45, 0.7164, 1.4019
8, 77.53, 0.6967, 1.4124
9, 76.91, 0.6786, 1.4231
10, 73.99, 0.7300, 1.3477
