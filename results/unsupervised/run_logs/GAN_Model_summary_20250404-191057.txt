==================================================
GAN FINAL MODEL TRAINING CONFIGURATION
==================================================

-------------------- Training Parameters --------------------
Batch Size: 64
Latent Dimension: 100
Epochs: 30

-------------------- Loss & Optimizers --------------------
Loss Function: BinaryCrossentropy

Generator Optimizer (Adam):
Learning Rate: {'module': 'keras.optimizers.schedules', 'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.0002, 'decay_steps': 300, 'decay_rate': 0.99, 'staircase': False, 'name': 'ExponentialDecay'}, 'registered_name': None}
Beta 1: 0.5

Discriminator Optimizer (Adam):
Learning Rate: {'module': 'keras.optimizers.schedules', 'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.0002, 'decay_steps': 300, 'decay_rate': 0.99, 'staircase': False, 'name': 'ExponentialDecay'}, 'registered_name': None}
Beta 1: 0.5
==================================================
MODEL ARCHITECTURES
==================================================

-------------------- Generator Architecture --------------------
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                        │ (None, 9216)                │         921,600 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization                  │ (None, 9216)                │          36,864 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu (LeakyReLU)              │ (None, 9216)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ reshape (Reshape)                    │ (None, 6, 6, 256)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose (Conv2DTranspose)   │ (None, 12, 12, 128)         │         294,912 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_1                │ (None, 12, 12, 128)         │             512 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_1 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose_1 (Conv2DTranspose) │ (None, 24, 24, 64)          │          73,728 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_2                │ (None, 24, 24, 64)          │             256 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_2 (LeakyReLU)            │ (None, 24, 24, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose_2 (Conv2DTranspose) │ (None, 48, 48, 32)          │          18,432 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_normalization_3                │ (None, 48, 48, 32)          │             128 │
│ (BatchNormalization)                 │                             │                 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_3 (LeakyReLU)            │ (None, 48, 48, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_transpose_3 (Conv2DTranspose) │ (None, 96, 96, 1)           │             289 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 1,346,721 (5.14 MB)
 Trainable params: 1,327,841 (5.07 MB)
 Non-trainable params: 18,880 (73.75 KB)


-------------------- Discriminator Architecture --------------------
Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                      │ (None, 48, 48, 32)          │             320 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_4 (LeakyReLU)            │ (None, 48, 48, 32)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (Conv2D)                    │ (None, 24, 24, 64)          │          18,496 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_5 (LeakyReLU)            │ (None, 24, 24, 64)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_2 (Conv2D)                    │ (None, 12, 12, 128)         │          73,856 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_6 (LeakyReLU)            │ (None, 12, 12, 128)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_3 (Conv2D)                    │ (None, 6, 6, 256)           │         295,168 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ leaky_re_lu_7 (LeakyReLU)            │ (None, 6, 6, 256)           │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (Flatten)                    │ (None, 9216)                │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (Dense)                      │ (None, 1)                   │           9,217 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 397,057 (1.51 MB)
 Trainable params: 397,057 (1.51 MB)
 Non-trainable params: 0 (0.00 B)


==================================================
TRAINING RESULTS FOLLOW BELOW
==================================================

Epoch, Time(s), Generator_Loss, Discriminator_Loss
1, 124.17, 2.1520, 0.6597
2, 98.28, 1.1764, 1.1517
3, 83.33, 1.2043, 1.0811
4, 97.72, 1.1290, 1.1384
5, 98.61, 1.2055, 1.0922
6, 98.70, 1.3641, 0.9933
7, 98.42, 1.4292, 0.9466
8, 90.80, 1.4807, 0.9706
9, 45.74, 1.6976, 0.8258
10, 68.19, 1.7124, 0.8670
11, 61.68, 1.6975, 0.8680
12, 67.92, 1.7062, 0.9050
13, 68.62, 1.5037, 1.0124
14, 68.84, 1.5213, 0.9831
15, 69.07, 1.5768, 0.9304
16, 67.60, 1.5203, 0.9871
17, 68.20, 1.5113, 0.9976
18, 64.25, 1.6043, 0.8787
19, 68.71, 1.5132, 0.9291
20, 64.95, 1.4635, 0.9595
21, 69.08, 1.5911, 0.9040
22, 64.22, 1.4025, 1.0320
23, 68.84, 1.5020, 0.9476
24, 67.80, 1.5417, 0.9278
25, 68.21, 1.5964, 0.9254
26, 62.18, 1.5533, 0.9758
27, 68.23, 1.5968, 0.8949
28, 70.06, 1.5420, 0.9377
29, 45.26, 1.4553, 1.0136
30, 64.88, 1.4897, 0.9846
